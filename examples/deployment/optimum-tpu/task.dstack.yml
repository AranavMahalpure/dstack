type: task
name: llama31-task-optimum-tpu
# This task runs Meta-Llama-3.1-8B with TGI
# Refer to Note section in examples/gpus/tpu/README.md for more information about the image.
image: sjbbihan/optimum-tpu:latest

# Required environment variables
env:
  - HUGGING_FACE_HUB_TOKEN
  - MODEL_ID=meta-llama/Meta-Llama-3.1-8B
commands:
  - text-generation-launcher --port 8000 --max-concurrent-requests 4 --max-input-tokens 128 --max-total-tokens 150 --max-batch-prefill-tokens 128

ports: [8000]

# Use either spot or on-demand instances
spot_policy: auto

resources:
  gpu: v5litepod-8